{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c445697ca9b61000f1b2da5b1cf96ddb1574ffb9a1e15cdac53084d5979e4566"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Notebook for preparing data for spine labelling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sag_path = '/home/donal/PhD/initial_spines/CT_models/data/all_verts/'\n",
    "coronal_projections_path = './images_coronal/all_projections/'\n",
    "sag_projections_path = './images_sagittal/all_projections/'\n",
    "data_list = '/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_all_forviewing.txt'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_verts = ['T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'L1', 'L2', 'L3', 'L4']"
   ]
  },
  {
   "source": [
    "## Functions for loading/checking data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def get_centre(pts_file):\n",
    "    \"\"\"\n",
    "    Find centre point of vertebral body from sagittal annotations\n",
    "    \"\"\"\n",
    "    with open(pts_file, 'r') as f:\n",
    "        text = f.readlines()\n",
    "        lines = [line.strip() for line in text]\n",
    "        start = lines.index('{')\n",
    "        end = lines.index('}')\n",
    "        points = lines[start+1:end]\n",
    "        top_y = [float(line.split(' ')[-1]) for line in points[0:10]]\n",
    "        bot_y = [float(line.split(' ')[-1]) for line in points[19:29]]\n",
    "        top_y.extend(bot_y)\n",
    "    return np.mean(top_y)\n",
    "\n",
    "def check_rejects(pts_dict):\n",
    "    # Check for overlapping annotations\n",
    "    reject_list = []\n",
    "    for key, val in pts_dict.items():\n",
    "        for vert, elem in val.items():\n",
    "            # Find nearest centre point\n",
    "            coords = list(val.values())\n",
    "            coords.remove(elem)\n",
    "            zipped_coords = list(zip(*coords))\n",
    "            near_neigh = sorted(\n",
    "                list(zipped_coords[-1]), key=lambda x: abs(x-elem[-1]))[0]\n",
    "            # Find distance between centroid for vert and nearest neighbour\n",
    "            dist = int(abs(elem[-1]-near_neigh))\n",
    "            if dist == 0:\n",
    "                print(key, vert)\n",
    "                reject_list.append(key)\n",
    "                continue\n",
    "    return reject_list\n",
    "\n",
    "def find_x_val(coronal_pts, tgt):\n",
    "    \"\"\"\n",
    "    Find x val in coronal projection by finding coronal midline\n",
    "    \"\"\"\n",
    "    with open(coronal_pts, 'r') as f:\n",
    "        text = f.readlines()\n",
    "        lines = [line.strip() for line in text]\n",
    "        start = lines.index('{')\n",
    "        end = lines.index('}')\n",
    "        points = lines[start+1:end]\n",
    "        y_vals = [float(line.split(' ')[-1]) for line in points]\n",
    "        x_vals = [float(line.split(' ')[0]) for line in points]\n",
    "    # Get top 2 closest values to sag. midpoint (y-axis)\n",
    "    mini = sorted(y_vals, key=lambda t: abs(t-tgt))[:2]\n",
    "    idx = [y_vals.index(val) for val in mini]\n",
    "    select_x = np.asarray(x_vals)[idx]\n",
    "    del_y = mini[0] - mini[1]\n",
    "    del_x = select_x[0]-select_x[1]\n",
    "    if del_x == 0:\n",
    "        return select_x[0]\n",
    "    else:\n",
    "        slope = del_y/del_x\n",
    "        b = mini[0]-slope*select_x[0]\n",
    "    #y=mx+b => x = (y-b)/m\n",
    "    return (tgt-b)/slope\n",
    "\n",
    "def get_id():\n",
    "    \"\"\"\n",
    "    Collect paths to point files, in a dict\n",
    "    \"\"\"\n",
    "    sag_files = [file for file in os.listdir(sag_path)]\n",
    "    pts_files = {}\n",
    "    with open(data_list, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        start = lines.index('{')\n",
    "        end = lines.index('}')\n",
    "        info_list = lines[start+1:end]\n",
    "        for line in info_list:\n",
    "            pts, img = line.split(':')\n",
    "            if '_Sag_' in pts:\n",
    "                id_ = pts.split('.')[0].split('_Sag_')[0]\n",
    "            else:\n",
    "                id_ = pts.split('.')[0].split('_midline_')[0]\n",
    "\n",
    "            matched_mip = [filename for filename in os.listdir(\n",
    "                coronal_projections_path) if id_ in filename]\n",
    "            for file in matched_mip:\n",
    "                id_ = file.split('.npy')[0]\n",
    "                vert_list = list(\n",
    "                    filter(lambda x: f'{id_}_midline' in x, sag_files))\n",
    "                if not vert_list:\n",
    "                    continue\n",
    "                else:\n",
    "                    pts_files[id_] = vert_list\n",
    "    return pts_files\n",
    "\n",
    "def get_points(pts_files):\n",
    "    \"\"\"\n",
    "     Get coordinates of each vertebral centre point\n",
    "    \"\"\"\n",
    "    pts_dict = {}\n",
    "    for key, val in pts_files.items():\n",
    "        name = f'{key}_kj'\n",
    "        pts_dict[name] = {}\n",
    "        for elem in val:\n",
    "            # Find name of vertebra\n",
    "            name_split = re.findall('[0-9a-zA-Z][^A-Z]*',\n",
    "                                    os.path.splitext(elem)[0])\n",
    "            vert = name_split[-1].split('_')[0]\n",
    "            # Get y-value of centre-point on saggital\n",
    "            coronal_filename = f'{name}.jpg.pts'\n",
    "            centre_point = get_centre(os.path.join(sag_path, elem))\n",
    "            # Get x-value\n",
    "            x_val = find_x_val(\n",
    "                f'/home/donal/PhD/initial_spines/CT_models/MIP/data/points/{coronal_filename}', centre_point)\n",
    "            pts_dict[name][vert] = (x_val, centre_point)\n",
    "\n",
    "    return pts_dict"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": []
  },
  {
   "source": [
    "## Collect Points "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 353 points files w/ matching MIP\n",
      "Found 353 vertebral annotations.\n"
     ]
    }
   ],
   "source": [
    "pts_files = get_id()\n",
    "print(f'Found {len(list(pts_files.keys()))} points files w/ matching MIP')\n",
    "pts_dict = get_points(pts_files)\n",
    "print(f'Found {len(list(pts_dict.keys()))} vertebral annotations.')"
   ]
  },
  {
   "source": [
    "## Convert to one-hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1 rejects.\n"
     ]
    }
   ],
   "source": [
    " vert_list = []\n",
    "# Convert vertebra names to one-hot\n",
    "for val in pts_dict.values():\n",
    "    vert_list.extend(list(val.keys()))\n",
    "all_verts = list(np.unique(vert_list))\n",
    "enc = LabelBinarizer()\n",
    "enc.fit(all_verts)\n",
    "enc.classes_ = ordered_verts\n",
    "# Check for overlapping annotations\n",
    "reject_list = set(check_rejects(pts_dict))\n",
    "# Add key to rejects -- Can't remember why I chose to reject this one...\n",
    "reject_list.add('23_05_2014_153_Sag')\n",
    "print(f'Found {len(reject_list)} rejects.')"
   ]
  },
  {
   "source": [
    "## Read pixel info, collected when MIPs were performed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Minimum pixel size across dataset: 0.3125 mm\n                                              Size (mm)\nName                                                   \n18_03_2015_20150318152008968_SRS00000_mip_WL   0.685000\nfr_580_LS_Sag_mip_WL                           0.781250\n29_05_2014_60_Sag_mip_WL                       0.781250\nfr_560_TS_Sag_mip_WL                           0.701172\n06_06_2014_502_LS_Sag_mip_WL                   0.800000\n"
     ]
    }
   ],
   "source": [
    " # Read pixel info\n",
    "pix_info = pd.read_csv(\n",
    "    '/home/donal/CT_volumes/pixel_size.csv', index_col='Name')\n",
    "min_pix = pix_info.loc[:, 'Size (mm)'].min()\n",
    "print(f'Minimum pixel size across dataset: {min_pix} mm')\n",
    "print(pix_info.head())"
   ]
  },
  {
   "source": [
    "# Prepare images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_images(pts_dict, rejects, pix_info, outpath='./data/annotated_sanity/', plot=False):\n",
    "    # Prepare data for Train/Test/Val split\n",
    "    cor_info_csv = './images_coronal/annotation_info.csv'\n",
    "    sag_info_csv = './images_sagittal/annotation_info.csv'\n",
    "    clean_path = '/home/donal/PhD/initial_spines/CT_models/FCN/data/clean_data.npz'\n",
    "    clean_data = np.load(clean_path)\n",
    "    id_list = [''.join(elem) for elem in clean_data['id']]\n",
    "    print(len(id_list))\n",
    "    print(id_list)\n",
    "    cor_info = pd.read_csv(cor_info_csv)\n",
    "    sag_info = pd.read_csv(sag_info_csv)\n",
    "    for key, val in pts_dict.items():\n",
    "        print(key)\n",
    "        if key.split('_kj')[0] not in rejects:\n",
    "            key = key.split('_kj')[0]\n",
    "            # Check if ID is in clean_data (i.e annotation is ok)\n",
    "            if key not in id_list:\n",
    "                print('Issue with image, skipping...')\n",
    "                continue\n",
    "            out_img_path = os.path.join(outpath, f'{key}_annotated.tiff')\n",
    "            # Load projection images\n",
    "            cor_filename = os.path.join(coronal_projections_path, f'{key}.npy')\n",
    "            cor_img = np.load(cor_filename)\n",
    "            sag_filename = os.path.join(sag_projections_path, f'{key}.npy')\n",
    "            sag_img = np.load(sag_filename)\n",
    "\n",
    "            # Get info from pre-processing images\n",
    "            cor = cor_info.loc[cor_info['Name'] == key]\n",
    "            cor_pad = literal_eval(cor.iloc[0]['Padding'])\n",
    "            cor_scale = literal_eval(cor.iloc[0]['Pixel Scaling'])\n",
    "            # Load vert annotations\n",
    "            vert_dict = {}\n",
    "            for vert, elem in val.items():\n",
    "                # Account for resampling to isotropic grid\n",
    "                x, y = (x*s for x, s in zip(elem, cor_scale))\n",
    "                y -= cor_pad[1]\n",
    "                vert_dict[vert] = y\n",
    "            \n",
    "            # Convert y coordinate to heatmap\n",
    "            gt_holder = np.zeros((*cor_img.shape[:2], len(ordered_verts)))\n",
    "            for vert, y in vert_dict.items():\n",
    "                channel = ordered_verts.index(vert)\n",
    "                x = np.linspace(0, 626, 626)\n",
    "                gauss = np.array(stats.norm.pdf(x, y, 10))[..., np.newaxis]\n",
    "                norm_gauss = (gauss - gauss.min())/(gauss.max()-gauss.min())*626\n",
    "                tmp = np.tile(norm_gauss, (1, 452))\n",
    "                gt_holder[..., channel] = tmp\n",
    "            \n",
    "            # Save heatmap to folder\n",
    "            np.save(f'./data/heatmaps/{key}.npy', gt_holder)\n",
    "\n",
    "\n",
    "            if plot:\n",
    "                fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "                ax = axes.ravel()\n",
    "                ax[0].axis('off')\n",
    "                ax[1].axis('off')\n",
    "                ax[2].axis('off')\n",
    "                ax[3].axis('off')\n",
    "                plt.tight_layout()\n",
    "                ax[0].imshow(cor_img)\n",
    "                ax[1].imshow(sag_img)\n",
    "                ax[2].imshow(cor_img)\n",
    "                ax[2].imshow(np.argmax(gt_holder, axis=-1), alpha=0.5)\n",
    "                ax[3].imshow(sag_img)\n",
    "                ax[3].imshow(np.argmax(gt_holder, axis=-1), alpha=0.5)\n",
    "                for vert, y in vert_dict.items():\n",
    "                    ax[0].axhline(y, linewidth=2, c='y')\n",
    "                    ax[0].text(0, y-5, vert, color='w')\n",
    "                    ax[1].axhline(y, linewidth=2, c='y')\n",
    "                    ax[1].text(0, y-5, vert, color='w')\n",
    "\n",
    "\n",
    "                #plt.close()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "346\n['01_06_2014_363_Sag', '01_06_2014_364_Sag', '01_06_2014_365_Sag', '01_06_2014_366_Sag', '01_06_2014_367_Sag', '01_06_2014_368_Sag', '02_06_2014_372_Sag', '02_06_2014_373_Sag', '02_06_2014_376_LS_Sag', '02_06_2014_378_Sag', '02_06_2014_379_Sag', '02_06_2014_380_Sag', '02_06_2014_381_Sag', '02_06_2014_383_LS_Sag', '02_06_2014_383_TS_Sag', '02_06_2014_385_Sag', '02_06_2014_386_Sag', '02_06_2014_387_Sag', '02_06_2014_388_Sag', '03_06_2014_389_Sag', '03_06_2014_390_Sag', '03_06_2014_391_Sag', '03_06_2014_392_LS_Sag', '03_06_2014_392_TS_Sag', '03_06_2014_393_Sag', '03_06_2014_394_Sag', '03_06_2014_395_Sag', '03_06_2014_396_Sag', '03_06_2014_397_Sag', '03_06_2014_398_Sag', '03_06_2014_399_TS_Sag', '03_06_2014_400_Sag', '03_06_2014_401_LS_Sag', '03_06_2014_401_TS_Sag', '03_06_2014_402_Sag', '03_06_2014_403_Sag', '03_06_2014_404_LS_Sag', '03_06_2014_404_TS_Sag', '03_06_2014_405_LS_Sag', '03_06_2014_405_TS_Sag', '03_06_2014_406_Sag', '03_06_2014_407_Sag', '04_06_2014_408_LS_Sag', '04_06_2014_408_TS_Sag', '04_06_2014_409_Sag', '04_06_2014_410_Sag', '04_06_2014_411_Sag', '04_06_2014_412_Sag', '04_06_2014_413_LS_Sag', '04_06_2014_413_TS_Sag', '04_06_2014_414_LS_Sag', '04_06_2014_414_LS_Sag_3mm', '04_06_2014_415_TS_Sag', '04_06_2014_416_CS_Sag', '04_06_2014_417_Sag', '04_06_2014_418_Sag', '04_06_2014_419_TS_Sag', '04_06_2014_422_Sag', '04_06_2014_423_Sag', '04_06_2014_424_Sag', '04_06_2014_425_Sag', '04_06_2014_426_LS_Sag', '04_06_2014_426_TS_Sag', '04_06_2014_427_TS_Sag', '04_06_2014_427_TS_Sag_ivc', 'fr_504_TS_Sag', 'fr_505_LS_Sag', 'fr_506_LS_Sag', 'fr_507_TS_Sag', 'fr_508_LS_Sag', 'fr_509_TS_Sag', 'fr_510_TS_LS_Sag', 'fr_511_LS_Sag', 'fr_513_LS_Sag', 'fr_513_TS_Sag', 'fr_514_LS_Sag', 'fr_517_LS_Sag', 'fr_518_LS_Sag', 'fr_518_TLS_LS_Sag', 'fr_521_TLS_LS_Sag', 'fr_523_LS_Sag', 'fr_523_TS_Sag', 'fr_524_LS_Sag', 'fr_524_TS_Sag', 'fr_526_LS_Sag', 'fr_528_LS_Sag', 'fr_529_LS_Sag', 'fr_532_TS_Sag', 'fr_533_LS_Sag', 'fr_533_TLS_Sag', 'fr_534_TS_Sag', 'fr_536_LS_Sag', '04_06_2014_431_Sag', '04_06_2014_432_Sag', '04_06_2014_433_Sag', '04_06_2014_436_Sag', '04_06_2014_437_Sag', '04_06_2014_439_Sag', '05_06_2014_440_LS_Sag', '15_05_2014_293_TS_Sag', '15_05_2014_294_CTS_Sag', '15_05_2014_295_LS_Sag', '15_05_2014_295_TS_Sag', '15_05_2014_296_Sag', '16_05_2014_249_Sag', '16_05_2014_250_CS_Sag', '16_05_2014_252_Sag', '16_05_2014_254_Sag', '16_05_2014_255_Sag', '16_05_2014_256_Sag_TLS', '16_05_2014_257_Sag', '16_05_2014_258_Sag', '16_05_2014_259_LS_Sag', '16_05_2014_260_Sag', '16_05_2014_261_Sag', '16_05_2014_262_Sag', '16_05_2014_264_Sag', '16_05_2014_265_LS_Sag', '16_05_2014_265_TS_Sag', '16_05_2014_266_Sag', '16_05_2014_267_Sag', '16_05_2014_268_Sag', '16_05_2014_269_Sag', '17_05_2014_241_Sag', '17_05_2014_247_Sag', '18_03_2015_20150318150213500_SRS00005', '18_03_2015_20150318151044687_SRS00000', '18_03_2015_20150318151341937_SRS00000', '18_03_2015_20150318151507421_SRS00000', '18_03_2015_20150318151758781_SRS00000', '18_03_2015_20150318152008968_SRS00000', '18_03_2015_20150318152358578_SRS00000', '18_03_2015_20150318152747953_SRS00001', '18_03_2015_20150319113614500_SRS00000', '18_03_2015_20150319115251343_SRS00000', '18_03_2015_20150319115452796_SRS00001', '18_03_2015_20150319115717984_SRS00000', '18_03_2015_20150319120307453_SRS00001', '18_03_2015_20150319120512281_SRS00000', '18_03_2015_20150319120713875_SRS00000', '18_03_2015_20150319121258156_SRS00000', '18_03_2015_20150319121427625_SRS00000', '18_03_2015_20150319121709796_SRS00001', '18_03_2015_20150319123927953_SRS00000', '18_03_2015_20150319124049921_SRS00000', '18_03_2015_20150319124343187_SRS00000', '18_03_2015_20150319124859640_SRS00000', 'fr_538_TS_Sag', 'fr_540_LS_Sag', 'fr_541_LS_Sag', 'fr_542_TS_Sag', 'fr_543_TS_Sag', 'fr_546_LS_Sag', 'fr_547_LS_Sag', 'fr_548_TS_Sag', 'fr_549_LS_Sag', 'fr_549_TS_Sag', 'fr_550_LS_Sag', 'fr_550_TS_Sag', 'fr_551_TS_Sag', 'fr_552_LS_Sag', 'fr_552_TS_Sag', 'fr_553_LS_Sag', 'fr_555_LS_Sag', 'fr_556_LS_Sag', 'fr_556_TS_Sag', 'fr_557_LS_Sag', 'fr_557_TS_Sag', 'fr_558_LS_Sag', 'fr_558_TS_Sag', 'fr_559_LS_Sag', 'fr_560_LS_Sag', 'fr_560_TS_Sag', 'fr_561_LS_Sag', 'fr_562_LS_Sag', 'fr_562_TS_Sag', 'fr_563_TS_Sag', '18_03_2015_20150319125133156_SRS00001', '18_03_2015_20150319125444171_SRS00000', '18_03_2015_20150319125615171_SRS00000', '18_03_2015_20150319125740781_SRS00000', '18_03_2015_20150319125954078_SRS00000', '18_03_2015_20150319131007984_SRS00000', '18_03_2015_20150319131132875_SRS00000', '18_03_2015_20150319131327578_SRS00000', '18_03_2015_20150319131835187_SRS00000', '18_03_2015_20150319131945625_SRS00000', '18_03_2015_20150319133424531_SRS00000', '18_03_2015_20150319133622375_SRS00000', '18_03_2015_20150319133841781_SRS00001', '18_03_2015_20150319134302703_SRS00000', '18_03_2015_20150319134531734_SRS00000', '18_03_2015_20150319134656906_SRS00000', '19_05_2014_218_Sag', '19_05_2014_219_Sag', '19_05_2014_221_Sag', '19_05_2014_222_Sag', '19_05_2014_224_Sag', '19_05_2014_226_Sag', '19_05_2014_227_Sag', '19_05_2014_229_Sag', '19_05_2014_230_Sag', '19_05_2014_232_Sag', '19_05_2014_233_Sag', '20_05_2014_204_Sag_TS', '20_05_2014_205_Sag', '20_05_2014_206_Sag_LS', '20_05_2014_209_Sag', '20_05_2014_210_Sag', '20_05_2014_214_Sag', '20_05_2014_215_Sag', '20_05_2014_216_Sag', '20_05_2014_217_Sag', '21_05_2014_181_Sag', '21_05_2014_183_Sag_TS', '21_05_2014_184_Sag_TS', '21_05_2014_186_Sag', '21_05_2014_187_Sag', '21_05_2014_188_Sag_LS', '21_05_2014_188_Sag_TS', '21_05_2014_189_Sag_LS', '21_05_2014_190_Sag', '21_05_2014_193_Sag', '21_05_2014_195_Sag_TS', '21_05_2014_196_Sag', '21_05_2014_197_Sag', '21_05_2014_198_Sag_V', '21_05_2014_198_Sag', '21_05_2014_199_Sag', '22_01_2015_20150122134607281_SRS00000', '22_01_2015_20150122135139671_SRS00000', '22_01_2015_20150122135354781_SRS00001', '22_05_2014_163_Sag', '22_05_2014_166_Sag', '22_05_2014_167_Sag_TS', '22_05_2014_167_Sag_LS', 'fr_564_LS_Sag', 'fr_567_LS_Sag', 'fr_568_LS_Sag', 'fr_569_TLS_Sag', 'fr_569_TS_Sag', 'fr_570_TS_Sag', 'fr_572_LS_Sag', 'fr_573_LS_Sag', 'fr_573_TS_Sag', 'fr_574_TS_Sag', 'fr_576_LS_Sag', 'fr_577_LS_Sag', 'fr_578_LS_Sag', 'fr_579_LS_Sag', 'fr_581_TS_Sag', 'fr_582_LS_Sag', 'fr_583_TS_Sag', 'fr_584_TS_LS_Sag', 'fr_585_TS_LS_Sag', 'fr_586_LS_Sag', 'fr_587_TS_Sag', 'fr_589_LS_Sag', 'fr_589_TS_Sag', 'fr_590_TS_Sag', 'fr_592_LS_Sag', 'fr_592_TS_Sag', 'fr_593_LS_Sag', 'fr_593_TS_Sag', 'fr_594_LS_Sag', '22_05_2014_168_Sag', '22_05_2014_169_Sag', '22_05_2014_170_Sag_LS', '22_05_2014_170_Sag_TS', '22_05_2014_171__Sag', '22_05_2014_172_Sag_LS', '22_05_2014_172_Sag_TS', '22_05_2014_173_Sag_TS', '22_05_2014_173_Sag_LS', '22_05_2014_175_Sag_IVC', '22_05_2014_175_Sag', '23_05_2014_138_Sag', '23_05_2014_140_Sag', '23_05_2014_145_Sag', '23_05_2014_147_Sag_TS', '23_05_2014_148_Sag', '23_05_2014_149_Sag_LS', '23_05_2014_150_Sag', '23_05_2014_151_Sag', '23_05_2014_154_Sag_CS', '23_05_2014_156_Sag_LS', '23_05_2014_157_Sag', '23_05_2014_159_Sag', '24_05_2014_133_Sag_TS', '24_05_2014_135_Sag', '24_05_2014_136_Sag', '25_05_2014_132_Sag_TS', '26_05_2014_129_Sag_TS', '27_05_2014_94_Sag_IVC_TS', '27_05_2014_96_Sag_IVC', '27_05_2014_96_Sag', '27_05_2014_99_Sag', '27_05_2014_102_Sag', '27_05_2014_105_Sag', '27_05_2014_106_Sag_TS', '27_05_2014_106_Sag_LS', '27_05_2014_107_Sag_LS', '27_05_2014_107_Sag_TS', '27_05_2014_109_Sag', '27_05_2014_110_Sag', '27_05_2014_111_Sag', '27_05_2014_112_Sag', '27_05_2014_120_Sag', '27_05_2014_126_Sag', '28_05_2014_67_Sag', '28_05_2014_68_Sag', '28_05_2014_71_Sag', '28_05_2014_72_Sag', '28_05_2014_73_Sag', '28_05_2014_74_Sag', '28_05_2014_76_Sag', '28_05_2014_78_Sag', '28_05_2014_79_Sag_LS', '28_05_2014_79_Sag_TS', '28_05_2014_80_Sag_LS', '28_05_2014_80_Sag_TS', '28_05_2014_81_Sag_TS', '28_05_2014_81_Sag_LS', 'fr_595_LS_Sag', 'fr_598_TS_Sag', 'fr_599_TS_LS_Sag', 'fr_600_LS_Sag', 'fr_602_LS_Sag', 'fr_603_LS_Sag', 'fr_603_TS_Sag', 'fr_604_TLS_LS_Sag', 'fr_604_TS_Sag', 'fr_605_TLS_LS_Sag', 'fr_606_TS_Sag', 'fr_607_TS_Sag', 'fr_608_LS_Sag', 'fr_609_TS_Sag', 'fr_610_TS_Sag', 'fr_611_LS_Sag', 'fr_613_LS_Sag', 'fr_613_TS_Sag', 'fr_615_TS_Sag', 'fr_617_LS_Sag', 'fr_617_TS_Sag', 'fr_620_LS_Sag', 'fr_628_LS_Sag']\n01_06_2014_363_Sag_kj\n"
     ]
    }
   ],
   "source": [
    "prep_images(pts_dict, reject_list, pix_info, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}