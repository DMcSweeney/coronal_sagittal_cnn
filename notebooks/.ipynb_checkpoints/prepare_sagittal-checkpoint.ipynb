{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ef3ebe-c655-4d01-aaab-2be2bcbe9fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7be8d5-99d3-4c4f-a1da-77d32c39db20",
   "metadata": {},
   "source": [
    "## Prep. Sagittal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb31eb7-6967-421e-a55c-53f0c0530dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_verts = ['T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'L1', 'L2', 'L3', 'L4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0720e4ab-9686-48aa-b0c3-1a2a15720d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "sag_path = '/home/donal/PhD/initial_spines/CT_models/data/all_verts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe84d4da-54eb-4fac-8390-7362291c71ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_list_q2.txt\n",
      "data_list_q4.txt\n",
      "data_list_q1.txt\n",
      "data_list_q3.txt\n",
      "['/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q2.txt', '/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q4.txt', '/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q1.txt', '/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q3.txt']\n"
     ]
    }
   ],
   "source": [
    "data_list_dir = '/home/donal/PhD/initial_spines/CT_models/data_lists/'\n",
    "data_lists = []\n",
    "for file in os.listdir(data_list_dir):\n",
    "    if '_q' in file:\n",
    "        print(file)\n",
    "        data_lists.append(data_list_dir + file)\n",
    "print(data_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0f82c71-cc3a-479f-818e-c1be94728369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(pts_file):\n",
    "    #Get vert. body annotations\n",
    "    with open(pts_file, 'r') as f:\n",
    "        text = f.readlines()\n",
    "        lines = [line.strip() for line in text]\n",
    "        start = lines.index('{')\n",
    "        end = lines.index('}')\n",
    "        x = [float(x.split(' ')[0]) for x in lines[start+1:end]]\n",
    "        y = [float(x.split(' ')[1]) for x in lines[start+1:end]]\n",
    "        points = (x, y)\n",
    "    return points\n",
    "\n",
    "def get_id(data_list):\n",
    "    \"\"\"\n",
    "    Collect paths to point files, in a dict\n",
    "    \"\"\"\n",
    "    sag_files = [file for file in os.listdir(sag_path)]\n",
    "    pts_files = {}\n",
    "    with open(data_list, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        for line in lines:\n",
    "            pts, img = line.split(':')\n",
    "            id_ = pts.split('.')[0]\n",
    "            vert_list = list(filter(lambda x: f'{id_}' in x, sag_files))\n",
    "            volume_name = id_.split('_midline')[0] + '.nii'\n",
    "            pts_files[volume_name] = vert_list\n",
    "    return pts_files\n",
    "\n",
    "def get_points(pts_files):\n",
    "    \"\"\"\n",
    "     Get + organise annotations\n",
    "    \"\"\"\n",
    "    mask_dict = {} #All landmark annotations for making a mask of vert.\n",
    "    for key, val in pts_files.items():\n",
    "        name = f\"{key.split('.')[0]}\"\n",
    "        mask_dict[name] = {}\n",
    "        for elem in val:\n",
    "            # Iterate over available vert. annotations\n",
    "            # Find name of vertebra\n",
    "            name_split = re.findall('[0-9a-zA-Z][^A-Z]*',\n",
    "                                    os.path.splitext(elem)[0])\n",
    "            vert = name_split[-1].split('_')[0]\n",
    "            # Get all landmark point annotations\n",
    "            points = get_mask(os.path.join(sag_path, elem))\n",
    "            mask_dict[name][vert] = points\n",
    "    return mask_dict\n",
    "\n",
    "\n",
    "def split_volumes(pts_files, fold):\n",
    "    root_dir = '/data/PAB_data/ct_volumes/'\n",
    "    out_dir = f'/data/PAB_data/volume_folds/{fold}/'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    print('Organising volumes')\n",
    "    for name in pts_files.keys():\n",
    "        shutil.copyfile(root_dir + name, out_dir + name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fb983d-01b5-4c8b-a56e-f950d21c5056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q2.txt\n",
      "FOLD: q2\n",
      "Found 87 points files\n",
      "Found 87 patients w. full vert. annotations.\n",
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q4.txt\n",
      "FOLD: q4\n",
      "Found 102 points files\n",
      "Found 102 patients w. full vert. annotations.\n",
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q1.txt\n",
      "FOLD: q1\n",
      "Found 100 points files\n",
      "Found 100 patients w. full vert. annotations.\n",
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q3.txt\n",
      "FOLD: q3\n",
      "Found 86 points files\n",
      "Found 86 patients w. full vert. annotations.\n"
     ]
    }
   ],
   "source": [
    "fold_data = {}\n",
    "for data_list in data_lists:\n",
    "    print(data_list)\n",
    "    num = data_list.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    pts_files = get_id(data_list)\n",
    "    print('FOLD:', num)\n",
    "    #split_volumes(pts_files, num)\n",
    "    \n",
    "    print(f'Found {len(list(pts_files.keys()))} points files')\n",
    "    mask_dict = get_points(pts_files)\n",
    "    print(f'Found {len(list(mask_dict.keys()))} patients w. full vert. annotations.')\n",
    "    fold_data[num] = mask_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a49632-bf03-4a39-b4ce-ef71f7916638",
   "metadata": {},
   "source": [
    "## Organise input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5215a3a2-d854-489b-9519-2971eef083fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c188a8e4-22a7-4ff0-9436-6955cb95253e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_verts = ['T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'L1', 'L2', 'L3', 'L4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ecb6ce4e-d874-47b6-9d55-3af507a23f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def points2frame(name, points_dict):\n",
    "    # Convert points into correct coordinate system (Scaling + padding)\n",
    "    vol = sitk.ReadImage(f'/data/PAB_data/ct_volumes/{name}.nii')\n",
    "    out_dict = {}\n",
    "    for vert, points in points_dict.items():\n",
    "        scale = vol.GetSpacing()[0]/1.25\n",
    "        padding =(512-vol.GetSize()[0]*scale)//2\n",
    "        x, y = points\n",
    "        x = [t * scale + padding for t in x]\n",
    "        y = [t* scale + padding for t in y]\n",
    "        out_dict[vert] = (x, y)\n",
    "    return out_dict\n",
    "\n",
    "def points2mask(points_dict):\n",
    "    # Convert points to mask by convexhull\n",
    "    mask_holder = mask_holder = np.zeros((512, 512, len(ordered_verts)+1), dtype=np.int16)\n",
    "    for vert, points in points_dict.items():\n",
    "        channel = ordered_verts.index(vert)\n",
    "        x, y = points\n",
    "        form_points = np.column_stack((x, y))\n",
    "        hull = ConvexHull(form_points)\n",
    "        indices = hull.vertices\n",
    "        hull_points = [(x, y) for x, y in form_points[indices, :]]\n",
    "        img = Image.new('I', (512, 512), 0)\n",
    "        ImageDraw.Draw(img).polygon(hull_points, outline=1, fill=1)\n",
    "        mask = np.array(img)\n",
    "        mask_holder[..., channel + 1] = np.flip(mask, axis=1)\n",
    "    return np.max(mask_holder, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5082f167-8726-4600-b6c0-ccaeddea0794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2\n",
      "q4\n",
      "q1\n",
      "q3\n"
     ]
    }
   ],
   "source": [
    "for fold, mask_dict in fold_data.items():\n",
    "    print(fold)\n",
    "    for name, points_dict in mask_dict.items():\n",
    "        midline = np.load(f'/data/PAB_data/images_sagittal/sagittal_midline/{fold}/{name}.npy').astype(np.float32)\n",
    "        midline /=255\n",
    "#         img = np.load(f'../images_sagittal/all_projections/{name}.npy').astype(np.float32)\n",
    "#         cat_img = np.stack([img[..., 0], midline, img[..., 2]], axis=-1)\n",
    "        points = points2frame(name, points_dict)\n",
    "        mask = points2mask(points)\n",
    "        os.makedirs(f'/data/PAB_data/vert_seg/{fold}/targets/', exist_ok=True)\n",
    "        os.makedirs(f'/data/PAB_data/vert_seg/{fold}/slices/', exist_ok=True)\n",
    "        np.save(f'/data/PAB_data/vert_seg/{fold}/targets/{name}.npy', mask)\n",
    "        np.save(f'/data/PAB_data/vert_seg/{fold}/slices/{name}.npy', midline)\n",
    "#         plt.figure(figsize=(10,10))\n",
    "#         plt.imshow(midline, cmap='gray')\n",
    "#         #plt.imshow(cat_img)\n",
    "#         #plt.imshow(img[..., 2])\n",
    "#         plt.imshow(mask, alpha=0.5)  \n",
    "        #break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
