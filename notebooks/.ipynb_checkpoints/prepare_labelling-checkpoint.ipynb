{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13f9c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import csv\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40998a58",
   "metadata": {},
   "source": [
    "## Prepare labelling data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325011e",
   "metadata": {},
   "source": [
    "Heatmaps, masks + coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c181a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_verts = ['T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11', 'T12', 'L1', 'L2', 'L3', 'L4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c210ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "sag_path = '/home/donal/PhD/initial_spines/CT_models/data/all_verts/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02b512b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_list_q2.txt\n",
      "data_list_q4.txt\n",
      "data_list_q1.txt\n",
      "data_list_q3.txt\n",
      "['/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q2.txt', '/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q4.txt', '/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q1.txt', '/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q3.txt']\n"
     ]
    }
   ],
   "source": [
    "data_list_dir = '/home/donal/PhD/initial_spines/CT_models/data_lists/'\n",
    "data_lists = []\n",
    "for file in os.listdir(data_list_dir):\n",
    "    if '_q' in file:\n",
    "        print(file)\n",
    "        data_lists.append(data_list_dir + file)\n",
    "print(data_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3726c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(pts_file):\n",
    "    #Get vert. body annotations\n",
    "    with open(pts_file, 'r') as f:\n",
    "        text = f.readlines()\n",
    "        lines = [line.strip() for line in text]\n",
    "        start = lines.index('{')\n",
    "        end = lines.index('}')\n",
    "        x = [float(x.split(' ')[0]) for x in lines[start+1:end]]\n",
    "        y = [float(x.split(' ')[1]) for x in lines[start+1:end]]\n",
    "        points = (x, y)\n",
    "    return points\n",
    "\n",
    "def get_id(data_list):\n",
    "    \"\"\"\n",
    "    Collect paths to point files, in a dict\n",
    "    \"\"\"\n",
    "    sag_files = [file for file in os.listdir(sag_path)]\n",
    "    pts_files = {}\n",
    "    with open(data_list, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "        for line in lines:\n",
    "            pts, img = line.split(':')\n",
    "            id_ = pts.split('.')[0]\n",
    "            vert_list = list(filter(lambda x: f'{id_}' in x, sag_files))\n",
    "            volume_name = id_.split('_midline')[0] + '.nii'\n",
    "            pts_files[volume_name] = vert_list\n",
    "    return pts_files\n",
    "\n",
    "def get_points(pts_files, level=None):\n",
    "    \"\"\"\n",
    "     Get + organise annotations\n",
    "    \"\"\"\n",
    "    mask_dict = {} #All landmark annotations for making a mask of vert.\n",
    "    for key, val in pts_files.items():\n",
    "        name = f\"{key.split('.')[0]}\"\n",
    "        mask_dict[name] = {}\n",
    "        for elem in val:\n",
    "            # Iterate over available vert. annotations\n",
    "            # Find name of vertebra\n",
    "            name_split = re.findall('[0-9a-zA-Z][^A-Z]*',\n",
    "                                    os.path.splitext(elem)[0])\n",
    "            vert = name_split[-1].split('_')[0]\n",
    "            if level is not None and vert != level: continue\n",
    "            # Get all landmark point annotations\n",
    "            points = get_mask(os.path.join(sag_path, elem))\n",
    "            mask_dict[name][vert] = points\n",
    "        # if level is not None and level not in mask_dict[name]:\n",
    "        #     del mask_dict[name]\n",
    "    return mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd1f62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q2.txt\n",
      "FOLD: q2\n",
      "Found 87 points files\n",
      "Found 87 patients w. full vert. annotations.\n",
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q4.txt\n",
      "FOLD: q4\n",
      "Found 102 points files\n",
      "Found 102 patients w. full vert. annotations.\n",
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q1.txt\n",
      "FOLD: q1\n",
      "Found 100 points files\n",
      "Found 100 patients w. full vert. annotations.\n",
      "/home/donal/PhD/initial_spines/CT_models/data_lists/data_list_q3.txt\n",
      "FOLD: q3\n",
      "Found 86 points files\n",
      "Found 86 patients w. full vert. annotations.\n"
     ]
    }
   ],
   "source": [
    "fold_data = {}\n",
    "for data_list in data_lists:\n",
    "    print(data_list)\n",
    "    num = data_list.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "    pts_files = get_id(data_list)\n",
    "    print('FOLD:', num)\n",
    "    print(f'Found {len(list(pts_files.keys()))} points files')\n",
    "    mask_dict = get_points(pts_files, level='T12')\n",
    "    print(f'Found {len(list(mask_dict.keys()))} patients w. full vert. annotations.')\n",
    "    fold_data[num] = mask_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67889668",
   "metadata": {},
   "source": [
    "### Masks + input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21c44d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "from scipy.spatial import ConvexHull, Delaunay\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ac146c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def points2frame(name, points_dict):\n",
    "    # Convert points into correct coordinate system (Scaling + padding)\n",
    "    vol = sitk.ReadImage(f'/data/PAB_data/ct_volumes/{name}.nii')\n",
    "    out_dict = {}\n",
    "    for vert, points in points_dict.items():\n",
    "        scale = vol.GetSpacing()[0]/1.25\n",
    "        padding =(512-vol.GetSize()[0]*scale)//2\n",
    "        x, y = points\n",
    "        x = [t * scale + padding for t in x]\n",
    "        y = [t* scale + padding for t in y]\n",
    "        out_dict[vert] = (x, y)\n",
    "    return out_dict\n",
    "\n",
    "def points2mask(points_dict):\n",
    "    # Convert points to mask by convexhull\n",
    "    mask_holder = mask_holder = np.zeros((512, 512, len(ordered_verts)+1), dtype=np.int16)\n",
    "    for vert, points in points_dict.items():\n",
    "        channel = ordered_verts.index(vert)\n",
    "        x, y = points\n",
    "        form_points = np.column_stack((x, y))\n",
    "        hull = ConvexHull(form_points)\n",
    "        indices = hull.vertices\n",
    "        hull_points = [(x, y) for x, y in form_points[indices, :]]\n",
    "        img = Image.new('I', (512, 512), 0)\n",
    "        ImageDraw.Draw(img).polygon(hull_points, outline=1, fill=1)\n",
    "        mask = np.array(img)\n",
    "        mask_holder[..., channel + 1] = np.flip(mask, axis=1)\n",
    "    return np.argmax(mask_holder, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d0486de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2\n",
      "q4\n",
      "q1\n",
      "q3\n"
     ]
    }
   ],
   "source": [
    "for fold, mask_dict in fold_data.items():\n",
    "    print(fold)\n",
    "    for name, points_dict in mask_dict.items():\n",
    "        midline = np.load(f'/data/PAB_data/images_sagittal/sagittal_midline/{fold}/{name}.npy').astype(np.float32)\n",
    "        midline /=255\n",
    "        img = np.load(f'../images_sagittal/all_projections/{name}.npy').astype(np.float32)\n",
    "        cat_img = np.stack([img[..., 0], midline, img[..., 2]], axis=-1)\n",
    "        points = points2frame(name, points_dict)\n",
    "        mask = points2mask(points)\n",
    "        os.makedirs(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/masks/', exist_ok=True)\n",
    "        os.makedirs(f'/data/PAB_data/vert_labelling_T12/{fold}/slices/', exist_ok=True)\n",
    "        np.save(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/masks/{name}.npy', mask)\n",
    "        np.save(f'/data/PAB_data/vert_labelling_T12/{fold}/slices/{name}.npy', cat_img)\n",
    "        # plt.figure(figsize=(10,10))\n",
    "        # #plt.imshow(midline, cmap='gray')\n",
    "        # plt.imshow(cat_img)\n",
    "        # plt.imshow(mask, alpha=0.5)  \n",
    "        #break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c8d68e",
   "metadata": {},
   "source": [
    "## Heatmaps + coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24cc426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import scipy.ndimage as snd\n",
    "from scipy.ndimage import gaussian_filter, distance_transform_edt\n",
    "import torch.nn.functional as F\n",
    "from operator import mul\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2899364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point2heatmap(points):\n",
    "    heatmap_holder = np.zeros((512, 512, len(ordered_verts)+1), dtype=np.float32)\n",
    "    for vert, point in points.items():\n",
    "        channel = ordered_verts.index(vert) + 1\n",
    "        x, y = point\n",
    "        xd = np.linspace(0, 512, 512)\n",
    "        #gauss = np.array(stats.norm.pdf(xd, y, 10))[..., np.newaxis]\n",
    "        #tmp = np.tile(gauss, (1, 512)).astype(np.float32)/512\n",
    "        #gauss = stats.multivariate_normal.pdf(m)\n",
    "        tmp = np.zeros((512, 512))\n",
    "        tmp[round(y), round(x)] = 1\n",
    "        tmp = gaussian_filter(tmp, sigma=5)\n",
    "        heatmap_holder[..., channel] = tmp\n",
    "    return heatmap_holder\n",
    "\n",
    "def get_coords(heatmap):\n",
    "    #norm_map = dsntnn.flat_softmax(heatmap)\n",
    "    return dsntnn.dsnt(heatmap, normalized_coordinates=False)\n",
    "\n",
    "def mask2distanceTransform(points):\n",
    "    # Convert points to mask by convexhull\n",
    "    edt_holder = np.zeros((512, 512, len(ordered_verts)+1), dtype=np.int16)\n",
    "    for vert, points in points.items():\n",
    "        channel = ordered_verts.index(vert)\n",
    "        x, y = points\n",
    "        form_points = np.column_stack((x, y))\n",
    "        hull = ConvexHull(form_points)\n",
    "        indices = hull.vertices\n",
    "        hull_points = [(x, y) for x, y in form_points[indices, :]]\n",
    "        img = Image.new('I', (512, 512), 0)\n",
    "        ImageDraw.Draw(img).polygon(hull_points, outline=1, fill=1)\n",
    "        mask = np.array(img)\n",
    "        edt_holder[..., channel + 1] = distance_transform_edt(1-np.flip(mask, axis=1))\n",
    "    return np.max(edt_holder, axis=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04241c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dsntnn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "078f14f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2\n",
      "(512, 512)\n",
      "q4\n",
      "(512, 512)\n",
      "q1\n",
      "(512, 512)\n",
      "q3\n",
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "for fold, mask_dict in fold_data.items():\n",
    "    print(fold)\n",
    "    for name, points_dict in mask_dict.items():\n",
    "        midline = np.load(f'/data/PAB_data/images_sagittal/sagittal_midline/{fold}/{name}.npy').astype(np.float32)\n",
    "        midline /= 255\n",
    "        \n",
    "        points = points2frame(name, points_dict)\n",
    "        # Euclidean distance transform\n",
    "        edt = mask2distanceTransform(points)\n",
    "        print(edt.shape)\n",
    "        centre_points = {}\n",
    "        for level, pts in points.items():\n",
    "            centre_points[level] = (512- np.mean(pts[0]), np.mean(pts[1]))\n",
    "        \n",
    "        heatmap = np.moveaxis(point2heatmap(centre_points), -1, 0)[np.newaxis]\n",
    "        #heatmap = dsntnn.flat_softmax(torch.tensor(heatmap)).numpy()\n",
    "        \n",
    "        dsnt_coords = get_coords(torch.tensor(heatmap)).numpy()\n",
    "        os.makedirs(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/heatmaps/', exist_ok=True)\n",
    "        os.makedirs(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/coordinates/', exist_ok=True)\n",
    "        os.makedirs(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/dist_transform/', exist_ok=True)\n",
    "        np.save(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/heatmaps/{name}.npy', np.squeeze(heatmap))\n",
    "        np.save(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/dist_transform/{name}.npy', edt)\n",
    "        \n",
    "        with open(f'/data/PAB_data/vert_labelling_T12/{fold}/targets/coordinates/{name}.csv', 'w') as f:\n",
    "            wrt = csv.writer(f, dialect='excel')\n",
    "            wrt.writerow(['Level', 'X', 'Y'])\n",
    "            for vert in ordered_verts:\n",
    "                if vert not in centre_points: continue\n",
    "                x, y = centre_points[vert]\n",
    "                wrt.writerow([vert, x, y])\n",
    "    \n",
    "#         cmap = sns.cubehelix_palette(start=1.5, rot=-1.5, gamma=0.8, as_cmap=True)\n",
    "#         fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "#         ax.imshow(midline, cmap='gray')\n",
    "#         #ax.imshow(np.argmax(heatmap, axis=1)[0], alpha=0.5)\n",
    "#         ax.imshow(np.max(heatmap, axis=1)[0], alpha=0.5, cmap=cmap)\n",
    "#         ax.imshow(edt, alpha=0.5, vmin=0, vmax=455, cmap='jet')\n",
    "# #         for vert, point in centre_points.items():\n",
    "# #             ax.scatter(*point, s=20, c='y', marker='*')\n",
    "# #             ax.text(*point, vert, c='r', size=15)\n",
    "    \n",
    "#         for channel in range(dsnt_coords.shape[1]):\n",
    "#             x, y = dsnt_coords[0, channel]\n",
    "#             ax.scatter(x, y, s=20, c='r', marker='+')\n",
    "#             if channel == 0: continue\n",
    "#             vert = ordered_verts[channel - 1]\n",
    "#             ax.text(x, y, vert, c='y', size=15)\n",
    "        #break\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
